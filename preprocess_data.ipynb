{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load cleaned data and preprocessing data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               image  emotion\n",
      "0  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      sad\n",
      "1  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...    anger\n",
      "2  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...  neutral\n",
      "3  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...     fear\n",
      "4  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...  content\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# # Load the CSV file into a DataFrame\n",
    "# df = pd.read_csv(\"cleaned_human_face_emotions.csv\")\n",
    "\n",
    "# Load the Parquet file (instead)\n",
    "df = pd.read_parquet(\"cleaned_human_face_emotions.parquet\")\n",
    "\n",
    "# Drop a column (for example, the \"qa\" column)\n",
    "df = df.drop(columns=[\"qa\"])\n",
    "\n",
    "# Print the first few rows of the updated DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9400 entries, 0 to 9399\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   image    9400 non-null   object\n",
      " 1   emotion  9400 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 147.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just have images in the first column with the emotion in the second column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 5640\n",
      "Test set size: 1880\n",
      "Validation set size: 1880\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate feature (X) and label (y)\n",
    "X = df['image']\n",
    "y = df['emotion']\n",
    "\n",
    "# Perform a stratified split to keep class distribution consistent\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,      # 80% training, 20% testing\n",
    "    random_state=42,    # for reproducibility\n",
    "    stratify=y          # important for classification\n",
    ")\n",
    "\n",
    "# Validation split from X_train if needed:\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.25,     # 25% of the training set (which is 20% of the total) -> 15% overall\n",
    "    random_state=42,\n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Test set size:\", len(X_test))\n",
    "print(\"Validation set size:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decoding and resizing images...\n",
      "X_train_array shape: (5640, 224, 224, 3)\n",
      "X_val_array shape: (1880, 224, 224, 3)\n",
      "X_test_array shape: (1880, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Image bytes -> numpy arrays\n",
    "def decode_images(image_series, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Takes a pandas Series of dictionaries, each containing {'bytes': ...}.\n",
    "    Decodes them into a list of NumPy arrays (RGB).\n",
    "    Resizes images to target_size.\n",
    "    Normalizes pixel values to [0, 1].\n",
    "\n",
    "    Returns:\n",
    "      - A NumPy array of shape (num_samples, target_size[0], target_size[1], 3)\n",
    "    \"\"\"\n",
    "    decoded_list = []\n",
    "    for item in image_series:\n",
    "        # item should be a dict like {'bytes': b'...'}\n",
    "        try:\n",
    "            img_bytes = item['bytes']\n",
    "            with Image.open(io.BytesIO(img_bytes)) as img:\n",
    "                # Convert to RGB if needed\n",
    "                img = img.convert('RGB')\n",
    "                # Resize\n",
    "                img = img.resize(target_size)\n",
    "                # Convert to array\n",
    "                arr = np.array(img, dtype=np.float32) / 255.0\n",
    "            decoded_list.append(arr)\n",
    "        except Exception as e:\n",
    "            # If there's a bad image, you might want to handle or skip it\n",
    "            print(\"Error decoding image:\", e)\n",
    "            # Optionally skip or handle it somehow. For now, let's skip:\n",
    "            # Continue with the loop\n",
    "            continue\n",
    "\n",
    "    return np.stack(decoded_list, axis=0)\n",
    "\n",
    "print(\"\\nDecoding and resizing images...\")\n",
    "\n",
    "# Decode train set\n",
    "X_train_array = decode_images(X_train, target_size=(224, 224))\n",
    "print(\"X_train_array shape:\", X_train_array.shape)\n",
    "\n",
    "# Decode val set\n",
    "X_val_array = decode_images(X_val, target_size=(224, 224))\n",
    "print(\"X_val_array shape:\", X_val_array.shape)\n",
    "\n",
    "# Decode test set\n",
    "X_test_array = decode_images(X_test, target_size=(224, 224))\n",
    "print(\"X_test_array shape:\",  X_test_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label classes found: ['anger' 'content' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise']\n",
      "Sample of encoded labels: [6 3 5 6 0 6 7 3 4 0]\n"
     ]
    }
   ],
   "source": [
    "# Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded   = label_encoder.transform(y_val)\n",
    "y_test_encoded  = label_encoder.transform(y_test)\n",
    "\n",
    "print(\"\\nLabel classes found:\", label_encoder.classes_)\n",
    "print(\"Sample of encoded labels:\", y_train_encoded[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
