{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_Hdzn0RNOe3"
      },
      "source": [
        "# Face Emotion Recognition\n",
        "\n",
        "https://huggingface.co/datasets/tukey/human_face_emotions_roboflow/viewer/default/train?p=1&views%5B%5D=train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GImiTJQNN4w1"
      },
      "source": [
        "# Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KGB-_X0ENAHH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "df = pd.read_parquet(\"hf://datasets/tukey/human_face_emotions_roboflow/data/train-00000-of-00001.parquet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RS-C4FYGNyuN"
      },
      "source": [
        "# Data Overview & Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6BqKKM0N3XI",
        "outputId": "c84e2b99-5e69-4814-bb3e-61c456fbde77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values per column:\n",
            "image    0\n",
            "qa       0\n",
            "dtype: int64\n",
            "\n",
            "Dataframe Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9400 entries, 0 to 9399\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   image   9400 non-null   object\n",
            " 1   qa      9400 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 147.0+ KB\n",
            "None\n",
            "\n",
            "First 5 rows of the dataset:\n",
            "                                               image  \\\n",
            "0  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   \n",
            "1  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   \n",
            "2  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   \n",
            "3  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   \n",
            "4  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   \n",
            "\n",
            "                                                  qa  \n",
            "0  [{'question': 'How does the person feel in the...  \n",
            "1  [{'question': 'How does the person feel in the...  \n",
            "2  [{'question': 'How does the person feel in the...  \n",
            "3  [{'question': 'How does the person feel in the...  \n",
            "4  [{'question': 'How does the person feel in the...  \n"
          ]
        }
      ],
      "source": [
        "# Standardize column names (strip whitespace, lower-case, replace spaces with underscores)\n",
        "df.columns = [col.strip().lower().replace(' ', '_') for col in df.columns]\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Missing values per column:\")\n",
        "print(df.isna().sum())\n",
        "\n",
        "# No missing values or duplicates, so we can proceed with the data as is\n",
        "\n",
        "# Print out summary information\n",
        "print(\"\\nDataframe Info:\")\n",
        "print(df.info())\n",
        "\n",
        "# Print the first few rows to inspect the data\n",
        "print(\"\\nFirst 5 rows of the dataset:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxRmSAs7TI6k",
        "outputId": "34b6a0d9-01e6-454f-b244-8446a5ff576c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Missing values per column:\n",
            "image    0\n",
            "qa       0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values in each column\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpsQexVtTM4d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9AqZbvTR0k9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5oYLwpbaR6io"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "\n",
        "def extract_emotion(qa_entry):\n",
        "    try:\n",
        "        # If the qa_entry is a string, strip it and parse as JSON.\n",
        "        if isinstance(qa_entry, str):\n",
        "            qa_entry = qa_entry.strip()\n",
        "            qa_data = json.loads(qa_entry)\n",
        "        else:\n",
        "            qa_data = qa_entry\n",
        "\n",
        "        # If the data is a numpy array, convert it to a list.\n",
        "        if isinstance(qa_data, np.ndarray):\n",
        "            qa_data = qa_data.tolist()\n",
        "\n",
        "        # Now you can check if it's a list or tuple using this condition.\n",
        "        if isinstance(qa_data, (list, tuple)) and len(qa_data) > 0:\n",
        "            return qa_data[0].get(\"answer\")\n",
        "        else:\n",
        "            print(\"Unexpected qa_data structure:\", qa_data, \"with type\", type(qa_data))\n",
        "    except Exception as e:\n",
        "        print(\"Error parsing qa entry:\", qa_entry, \"\\nError:\", e)\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61O0wFYbPKy9",
        "outputId": "7f6a8077-be5f-432c-865a-098dbc5abc46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  qa  emotion\n",
            "0  [{'question': 'How does the person feel in the...      sad\n",
            "1  [{'question': 'How does the person feel in the...    anger\n",
            "2  [{'question': 'How does the person feel in the...  neutral\n",
            "3  [{'question': 'How does the person feel in the...     fear\n",
            "4  [{'question': 'How does the person feel in the...  content\n"
          ]
        }
      ],
      "source": [
        "# Assuming df is your DataFrame that includes the 'qa' column\n",
        "df[\"emotion\"] = df[\"qa\"].apply(extract_emotion)\n",
        "\n",
        "# Verify the new column\n",
        "print(df[[\"qa\", \"emotion\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApSH2Dy9Ta9S",
        "outputId": "d8690b65-6353-4984-cc47-3a00b2bb629d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Unique emotion labels:\n",
            "['sad' 'anger' 'neutral' 'fear' 'content' 'happy' 'disgust' 'surprise']\n",
            "\n",
            "Distribution of emotion labels:\n",
            "emotion\n",
            "surprise    1238\n",
            "neutral     1225\n",
            "sad         1184\n",
            "fear        1181\n",
            "anger       1175\n",
            "disgust     1165\n",
            "content     1144\n",
            "happy       1088\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check unique values and distribution of facial emotion labels\n",
        "if 'emotion' in df.columns:\n",
        "    print(\"\\nUnique emotion labels:\")\n",
        "    print(df['emotion'].unique())\n",
        "\n",
        "    print(\"\\nDistribution of emotion labels:\")\n",
        "    print(df['emotion'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3IdvF_4gTfrk"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example: Plot a histogram for a numeric column, adjust 'score' to the relevant column name\n",
        "if 'score' in df.columns:\n",
        "    plt.hist(df['score'].dropna(), bins=30, edgecolor='k')\n",
        "    plt.xlabel(\"Score\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.title(\"Histogram of Scores\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIh1nhSkTqb-",
        "outputId": "0500dfd4-0da1-4ae6-b295-21654994f554"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               image  emotion\n",
            "0  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      sad\n",
            "1  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...    anger\n",
            "2  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...  neutral\n",
            "3  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...     fear\n",
            "4  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...  content\n"
          ]
        }
      ],
      "source": [
        "# Optionally, save the cleaned dataframe to disk as a new parquet file or CSV\n",
        "df.to_parquet(\"cleaned_human_face_emotions.parquet\")\n",
        "# Alternatively, you can save as CSV:\n",
        "# df.to_csv(\"cleaned_human_face_emotions.csv\", index=False)\n",
        "\n",
        "# drop qa column\n",
        "df.drop(columns=[\"qa\"], inplace=True)\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "verJk70Osn1p"
      },
      "source": [
        "Now we just have images in the first column with the emotion in the second column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S29bqfcisvkF",
        "outputId": "e82f13eb-d09f-4daf-e8b6-befaeb7bb3d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: 5640\n",
            "Test set size: 1880\n",
            "Validation set size: 1880\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separate feature (X) and label (y)\n",
        "X = df['image']\n",
        "y = df['emotion']\n",
        "\n",
        "# Perform a stratified split to keep class distribution consistent\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,      # 80% training, 20% testing\n",
        "    random_state=42,    # for reproducibility\n",
        "    stratify=y          # important for classification\n",
        ")\n",
        "\n",
        "# Validation split from X_train if needed:\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    test_size=0.25,     # 25% of the training set (which is 20% of the total) -> 15% overall\n",
        "    random_state=42,\n",
        "    stratify=y_train\n",
        ")\n",
        "\n",
        "print(\"Training set size:\", len(X_train))\n",
        "print(\"Test set size:\", len(X_test))\n",
        "print(\"Validation set size:\", len(X_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Axs_6JBfvjIj",
        "outputId": "8907b8ca-db5c-426d-9477-5cdd0002077f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Decoding and resizing images...\n",
            "X_train_array shape: (5640, 224, 224, 3)\n",
            "X_val_array shape: (1880, 224, 224, 3)\n",
            "X_test_array shape: (1880, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "# Image bytes -> numpy arrays\n",
        "def decode_images(image_series, target_size=(224, 224)):\n",
        "    \"\"\"\n",
        "    Takes a pandas Series of dictionaries, each containing {'bytes': ...}.\n",
        "    Decodes them into a list of NumPy arrays (RGB).\n",
        "    Resizes images to target_size.\n",
        "    Normalizes pixel values to [0, 1].\n",
        "\n",
        "    Returns:\n",
        "      - A NumPy array of shape (num_samples, target_size[0], target_size[1], 3)\n",
        "    \"\"\"\n",
        "    decoded_list = []\n",
        "    for item in image_series:\n",
        "        # item should be a dict like {'bytes': b'...'}\n",
        "        try:\n",
        "            img_bytes = item['bytes']\n",
        "            with Image.open(io.BytesIO(img_bytes)) as img:\n",
        "                # Convert to RGB if needed\n",
        "                img = img.convert('RGB')\n",
        "                # Resize\n",
        "                img = img.resize(target_size)\n",
        "                # Convert to array\n",
        "                arr = np.array(img, dtype=np.float32) / 255.0\n",
        "            decoded_list.append(arr)\n",
        "        except Exception as e:\n",
        "            # If there's a bad image, you might want to handle or skip it\n",
        "            print(\"Error decoding image:\", e)\n",
        "            # Optionally skip or handle it somehow. For now, let's skip:\n",
        "            # Continue with the loop\n",
        "            continue\n",
        "\n",
        "    return np.stack(decoded_list, axis=0)\n",
        "\n",
        "print(\"\\nDecoding and resizing images...\")\n",
        "\n",
        "# Decode train set\n",
        "X_train_array = decode_images(X_train, target_size=(224, 224))\n",
        "print(\"X_train_array shape:\", X_train_array.shape)\n",
        "\n",
        "# Decode val set\n",
        "X_val_array = decode_images(X_val, target_size=(224, 224))\n",
        "print(\"X_val_array shape:\", X_val_array.shape)\n",
        "\n",
        "# Decode test set\n",
        "X_test_array = decode_images(X_test, target_size=(224, 224))\n",
        "print(\"X_test_array shape:\", X_test_array.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkTPeqPcxluw",
        "outputId": "f5ef3f62-9d4a-46a2-e4c8-a65a10b4b013"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Label classes found: ['anger' 'content' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise']\n",
            "Sample of encoded labels: [6 3 5 6 0 6 7 3 4 0]\n"
          ]
        }
      ],
      "source": [
        "# Encode labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_val_encoded   = label_encoder.transform(y_val)\n",
        "y_test_encoded  = label_encoder.transform(y_test)\n",
        "\n",
        "print(\"\\nLabel classes found:\", label_encoder.classes_)\n",
        "print(\"Sample of encoded labels:\", y_train_encoded[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "cUbjnsEEyVTa",
        "outputId": "507bf7c9-5fce-40f6-d970-5c6dc2334141"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,248</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │        \u001b[38;5;34m10,248\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,268,232</span> (8.65 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,268,232\u001b[0m (8.65 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,248</span> (40.03 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,248\u001b[0m (40.03 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 186ms/step - accuracy: 0.2082 - loss: 2.1595 - val_accuracy: 0.3154 - val_loss: 1.8075\n",
            "Epoch 2/5\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 167ms/step - accuracy: 0.3333 - loss: 1.7945 - val_accuracy: 0.3463 - val_loss: 1.7361\n",
            "Epoch 3/5\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 170ms/step - accuracy: 0.3668 - loss: 1.6936 - val_accuracy: 0.3191 - val_loss: 1.7568\n",
            "Epoch 4/5\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 175ms/step - accuracy: 0.4040 - loss: 1.5991 - val_accuracy: 0.3596 - val_loss: 1.7115\n",
            "Epoch 5/5\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 243ms/step - accuracy: 0.4333 - loss: 1.5305 - val_accuracy: 0.3681 - val_loss: 1.6924\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 236ms/step - accuracy: 0.3545 - loss: 1.7492\n",
            "\n",
            "Test Loss: 1.7052\n",
            "Test Accuracy: 0.3686\n",
            "Epoch 1/5\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 854ms/step - accuracy: 0.2605 - loss: 2.0964 - val_accuracy: 0.3383 - val_loss: 1.8724\n",
            "Epoch 2/5\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 912ms/step - accuracy: 0.3707 - loss: 1.7002 - val_accuracy: 0.3537 - val_loss: 1.8873\n",
            "Epoch 3/5\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 791ms/step - accuracy: 0.4339 - loss: 1.5407 - val_accuracy: 0.3553 - val_loss: 1.8478\n",
            "Epoch 4/5\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 763ms/step - accuracy: 0.4786 - loss: 1.3938 - val_accuracy: 0.3819 - val_loss: 1.7553\n",
            "Epoch 5/5\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 794ms/step - accuracy: 0.5125 - loss: 1.2992 - val_accuracy: 0.3957 - val_loss: 1.6829\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 130ms/step - accuracy: 0.3816 - loss: 1.8082\n",
            "\n",
            "Final Test Loss after fine-tuning: 1.7172\n",
            "Final Test Accuracy after fine-tuning: 0.4005\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Suppose you have: (224, 224, 3) images\n",
        "# If you used a different size (e.g. 160x160 for MobileNet), be consistent\n",
        "\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# 1) Load a MobileNetV2 (or EfficientNet, ResNet, etc.) without its top layers\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "# 2) Freeze the base_model so we only train the new head first\n",
        "base_model.trainable = False\n",
        "\n",
        "# 3) Build your classifier on top\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 4) Train the new top layers\n",
        "history = model.fit(\n",
        "    X_train_array, y_train_encoded,\n",
        "    validation_data=(X_val_array, y_val_encoded),\n",
        "    epochs=5,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_acc = model.evaluate(X_test_array, y_test_encoded)\n",
        "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# 5) (Optional) Fine-tune deeper layers\n",
        "# Unfreeze part (or all) of base_model and re-compile with a lower learning rate\n",
        "base_model.trainable = True\n",
        "# You can selectively unfreeze only some layers:\n",
        "# for layer in base_model.layers[:100]:\n",
        "#     layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),  # smaller LR for fine-tuning\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_fine = model.fit(\n",
        "    X_train_array, y_train_encoded,\n",
        "    validation_data=(X_val_array, y_val_encoded),\n",
        "    epochs=5,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_test_array, y_test_encoded)\n",
        "print(f\"\\nFinal Test Loss after fine-tuning: {test_loss:.4f}\")\n",
        "print(f\"Final Test Accuracy after fine-tuning: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the model in the native TensorFlow SavedModel format.\n",
        "model.save(\"saved_MobileNetV2.keras\")  # Use .keras extension for the Keras format.\n",
        "\n",
        "# Load the model later.\n",
        "loaded_model = tf.keras.models.load_model(\"saved_MobileNetV2.keras\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
