{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Emotion Recognition using VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "from PIL import Image\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg16_preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Optional: Configure GPU memory growth if needed\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   try:\n",
    "#     for gpu in gpus:\n",
    "#       tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#     logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#     print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#   except RuntimeError as e:\n",
    "#     print(e)\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load Data from Hugging Face Hub\n",
    "DATASET_PATH = \"hf://datasets/tukey/human_face_emotions_roboflow/data/train-00000-of-00001.parquet\"\n",
    "try:\n",
    "    df = pd.read_parquet(DATASET_PATH)\n",
    "    print(f\"Data loaded successfully from {DATASET_PATH}.\")\n",
    "    print(f\"Initial shape: {df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    # Handle error, e.g., exit or try loading locally\n",
    "    df = pd.DataFrame() # Assign empty dataframe to avoid further errors if loading fails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Overview & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Chunk 3: Clean Data and Extract Labels\n",
    "if not df.empty:\n",
    "    # Standardize column names\n",
    "    df.columns = [col.strip().lower().replace(' ', '_') for col in df.columns]\n",
    "\n",
    "    # Function to extract emotion label\n",
    "    def extract_emotion(qa_entry):\n",
    "        try:\n",
    "            if isinstance(qa_entry, str):\n",
    "                qa_entry = qa_entry.strip()\n",
    "                qa_data = json.loads(qa_entry)\n",
    "            else:\n",
    "                qa_data = qa_entry\n",
    "\n",
    "            if isinstance(qa_data, np.ndarray):\n",
    "                qa_data = qa_data.tolist()\n",
    "\n",
    "            if isinstance(qa_data, (list, tuple)) and len(qa_data) > 0:\n",
    "                answer = qa_data[0].get(\"answer\")\n",
    "                if isinstance(answer, str):\n",
    "                    return answer.lower().strip() # Standardize labels\n",
    "                else:\n",
    "                    # print(f\"Unexpected answer type: {answer}, type: {type(answer)} in entry: {qa_entry}\")\n",
    "                    return None\n",
    "            else:\n",
    "                # print(f\"Unexpected qa_data structure: {qa_data}, type: {type(qa_data)}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            # print(f\"Error parsing qa entry: {qa_entry}, \\nError: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Apply the function\n",
    "    df[\"emotion\"] = df[\"qa\"].apply(extract_emotion)\n",
    "\n",
    "    # Check and handle missing values\n",
    "    print(\"\\nMissing values BEFORE handling:\")\n",
    "    print(df.isna().sum())\n",
    "    initial_rows = len(df)\n",
    "    df.dropna(subset=['image', 'emotion'], inplace=True) # Drop if image or extracted emotion is missing\n",
    "    print(f\"Dropped {initial_rows - len(df)} rows due to missing image or emotion labels.\")\n",
    "    print(\"\\nMissing values AFTER handling:\")\n",
    "    print(df.isna().sum())\n",
    "\n",
    "\n",
    "    # Drop the original 'qa' column\n",
    "    if 'qa' in df.columns:\n",
    "        df.drop(columns=[\"qa\"], inplace=True)\n",
    "\n",
    "    # Display info and head\n",
    "    print(\"\\nCleaned Dataframe Info:\")\n",
    "    df.info()\n",
    "    print(\"\\nCleaned Dataframe Head:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # Check unique values and distribution\n",
    "    print(\"\\nUnique emotion labels:\")\n",
    "    unique_labels = df['emotion'].unique()\n",
    "    print(unique_labels)\n",
    "    num_classes = len(unique_labels)\n",
    "    print(f\"\\nNumber of unique labels: {num_classes}\")\n",
    "\n",
    "    print(\"\\nDistribution of emotion labels:\")\n",
    "    print(df['emotion'].value_counts())\n",
    "else:\n",
    "    print(\"DataFrame is empty, skipping cleaning steps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    X = df['image']\n",
    "    y = df['emotion']\n",
    "\n",
    "    # Stratified split into Train (60%), Validation (20%), Test (20%)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.4,\n",
    "        random_state=42,\n",
    "        stratify=y\n",
    "    )\n",
    "\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp,\n",
    "        test_size=0.5,\n",
    "        random_state=42,\n",
    "        stratify=y_temp\n",
    "    )\n",
    "\n",
    "    print(f\"\\nData Split:\")\n",
    "    print(f\"Training set size: {len(X_train)}\")\n",
    "    print(f\"Validation set size: {len(X_val)}\")\n",
    "    print(f\"Test set size: {len(X_test)}\")\n",
    "else:\n",
    "    print(\"DataFrame is empty, skipping data splitting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image Preprocessing & Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Image Decoding Function\n",
    "def decode_images(image_series, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Decodes image bytes from a pandas Series into NumPy arrays.\n",
    "    Handles potential errors during decoding.\n",
    "    Returns decoded images (uint8) and indices of valid images.\n",
    "    \"\"\"\n",
    "    decoded_list = []\n",
    "    valid_indices = []\n",
    "    original_indices = image_series.index\n",
    "\n",
    "    print(f\"Attempting to decode {len(image_series)} images...\")\n",
    "    processed_count = 0\n",
    "    error_count = 0\n",
    "\n",
    "    for i, item in enumerate(image_series):\n",
    "        try:\n",
    "            img_bytes = item['bytes']\n",
    "            with Image.open(io.BytesIO(img_bytes)) as img:\n",
    "                img = img.convert('RGB') # Ensure 3 channels\n",
    "                img = img.resize(target_size, Image.Resampling.LANCZOS) # Use LANCZOS for quality\n",
    "                # Keep as uint8 for VGG16 preprocessing\n",
    "                arr = np.array(img, dtype=np.uint8)\n",
    "            decoded_list.append(arr)\n",
    "            valid_indices.append(original_indices[i])\n",
    "            processed_count += 1\n",
    "        except Exception as e:\n",
    "            # print(f\"Error decoding image at index {original_indices[i]}: {e}. Skipping.\")\n",
    "            error_count += 1\n",
    "            continue\n",
    "        # Optional: Print progress periodically\n",
    "        # if (i + 1) % 500 == 0:\n",
    "        #     print(f\"  Processed {i+1}/{len(image_series)} images...\")\n",
    "\n",
    "    print(f\"Successfully decoded: {processed_count}, Errors: {error_count}\")\n",
    "\n",
    "    if not decoded_list:\n",
    "        return np.array([]), []\n",
    "\n",
    "    return np.stack(decoded_list, axis=0), valid_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Apply Decoding and Filter Labels\n",
    "if 'X_train' in locals(): # Check if splitting was done\n",
    "    TARGET_SIZE = (224, 224)\n",
    "    print(\"\\nDecoding Training Images...\")\n",
    "    X_train_array, train_valid_indices = decode_images(X_train, target_size=TARGET_SIZE)\n",
    "    print(\"\\nDecoding Validation Images...\")\n",
    "    X_val_array, val_valid_indices = decode_images(X_val, target_size=TARGET_SIZE)\n",
    "    print(\"\\nDecoding Test Images...\")\n",
    "    X_test_array, test_valid_indices = decode_images(X_test, target_size=TARGET_SIZE)\n",
    "\n",
    "    print(f\"\\nX_train_array shape: {X_train_array.shape if X_train_array.size > 0 else 'Empty'}\")\n",
    "    print(f\"X_val_array shape: {X_val_array.shape if X_val_array.size > 0 else 'Empty'}\")\n",
    "    print(f\"X_test_array shape: {X_test_array.shape if X_test_array.size > 0 else 'Empty'}\")\n",
    "\n",
    "    # Filter labels corresponding to successfully decoded images\n",
    "    y_train = y_train.loc[train_valid_indices]\n",
    "    y_val = y_val.loc[val_valid_indices]\n",
    "    y_test = y_test.loc[test_valid_indices]\n",
    "\n",
    "    print(f\"\\nFiltered label counts:\")\n",
    "    print(f\"y_train: {len(y_train)}\")\n",
    "    print(f\"y_val: {len(y_val)}\")\n",
    "    print(f\"y_test: {len(y_test)}\")\n",
    "\n",
    "    # Check if any set became empty after filtering bad images\n",
    "    if X_train_array.size == 0 or X_val_array.size == 0 or X_test_array.size == 0:\n",
    "        raise ValueError(\"One or more data splits empty after image decoding. Check data source/errors.\")\n",
    "else:\n",
    "    print(\"Skipping image decoding as data splits not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Encode Labels\n",
    "if 'y_train' in locals():\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    y_val_encoded   = label_encoder.transform(y_val)\n",
    "    y_test_encoded  = label_encoder.transform(y_test)\n",
    "\n",
    "    # Recalculate num_classes based on fitted encoder\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    print(\"\\nLabel classes found:\", label_encoder.classes_)\n",
    "    print(\"Number of classes:\", num_classes)\n",
    "    print(\"Sample of encoded labels (train):\", y_train_encoded[:10])\n",
    "else:\n",
    "    print(\"Skipping label encoding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Building (VGG16 with Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Chunk 8: Define Data Augmentation and Load Base Model\n",
    "IMG_SHAPE = TARGET_SIZE + (3,)\n",
    "\n",
    "# Data Augmentation Layer\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomContrast(0.1),\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "# Load VGG16 base model\n",
    "try:\n",
    "    base_model = vgg16.VGG16(\n",
    "        input_shape=IMG_SHAPE,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    # Freeze the base model initially\n",
    "    base_model.trainable = False\n",
    "    print(\"VGG16 base model loaded and frozen.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading base model: {e}\")\n",
    "    base_model = None # Set to None to prevent errors later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Build Full Model\n",
    "if base_model is not None and 'num_classes' in locals():\n",
    "    inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
    "    x = data_augmentation(inputs)\n",
    "    # Use VGG16 preprocessing (expects uint8 0-255)\n",
    "    x = vgg16_preprocess_input(x)\n",
    "    x = base_model(x, training=False) # Run base in inference mode initially\n",
    "    x = layers.GlobalAveragePooling2D(name=\"global_avg_pool\")(x)\n",
    "    x = layers.Dropout(0.2, name=\"top_dropout\")(x) # Regularization dropout\n",
    "    outputs = layers.Dense(num_classes, activation='softmax', name=\"output_dense\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    # Compile the model for initial training\n",
    "    initial_learning_rate = 0.001\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=initial_learning_rate),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    print(\"\\nModel built successfully.\")\n",
    "    model.summary()\n",
    "else:\n",
    "    print(\"Skipping model building due to previous errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Initial Training (Train the Head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Initial Model Training\n",
    "if 'model' in locals() and X_train_array.size > 0:\n",
    "    INITIAL_EPOCHS = 50 # Adjust as needed\n",
    "    BATCH_SIZE = 32     # Adjust based on GPU memory\n",
    "\n",
    "    # EarlyStopping Callback\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5, # Stop if val_loss doesn't improve for 5 epochs\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(f\"\\nStarting initial training for up to {INITIAL_EPOCHS} epochs...\")\n",
    "    history = model.fit(\n",
    "        X_train_array, y_train_encoded,\n",
    "        epochs=INITIAL_EPOCHS,\n",
    "        validation_data=(X_val_array, y_val_encoded),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    # Evaluate after initial training\n",
    "    loss0, accuracy0 = model.evaluate(X_val_array, y_val_encoded, verbose=0)\n",
    "    print(f\"\\nInitial training complete (or stopped early).\")\n",
    "    print(f\"Initial training - Validation Loss: {loss0:.4f}\")\n",
    "    print(f\"Initial training - Validation Accuracy: {accuracy0:.4f}\")\n",
    "else:\n",
    "    print(\"Skipping initial training due to previous errors or empty data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Fine-tuning (Adjusted Strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare for Fine-tuning (Unfreeze Layers)\n",
    "if 'model' in locals() and 'history' in locals():\n",
    "    # Unfreeze the base model first\n",
    "    base_model.trainable = True\n",
    "\n",
    "    # Determine how many layers are in the base model\n",
    "    total_layers = len(base_model.layers)\n",
    "    print(f\"\\nTotal layers in base model: {total_layers}\")\n",
    "\n",
    "    # Decide layers to fine-tune (e.g., unfreeze top 30)\n",
    "    fine_tune_layers_count = 30\n",
    "    fine_tune_from_layer_index = total_layers - fine_tune_layers_count\n",
    "    print(f\"Fine-tuning the top {fine_tune_layers_count} layers (from index {fine_tune_from_layer_index} onwards).\")\n",
    "\n",
    "    # Freeze all layers before the `fine_tune_from_layer_index`\n",
    "    for layer in base_model.layers[:fine_tune_from_layer_index]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Re-compile with a very low learning rate\n",
    "    fine_tune_learning_rate = 1e-5\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=fine_tune_learning_rate),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    print(\"\\nModel Summary after setting fine-tuning layers:\")\n",
    "    model.summary()\n",
    "else:\n",
    "    print(\"\\nSkipping fine-tuning setup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Run Fine-tuning Training\n",
    "if 'model' in locals() and 'history' in locals() and base_model.trainable: # Check if fine-tuning was set up\n",
    "    FINE_TUNE_EPOCHS = 35 # Adjust as needed\n",
    "    start_epoch_ft = history.epoch[-1] + 1 if history.epoch else 0\n",
    "    total_epochs_target = start_epoch_ft + FINE_TUNE_EPOCHS\n",
    "\n",
    "    print(f\"\\nStarting fine-tuning from epoch {start_epoch_ft} up to {total_epochs_target-1}...\")\n",
    "\n",
    "    # Use a new EarlyStopping instance\n",
    "    early_stopping_ft = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Check input data type again before fitting\n",
    "    print(f\"Fine-tuning input data type: {X_train_array.dtype}\") # Should be uint8\n",
    "\n",
    "    history_fine = model.fit(\n",
    "        X_train_array, y_train_encoded,\n",
    "        epochs=total_epochs_target,\n",
    "        initial_epoch=start_epoch_ft,\n",
    "        validation_data=(X_val_array, y_val_encoded),\n",
    "        batch_size=BATCH_SIZE, # Consider reducing batch size if memory issues arise\n",
    "        callbacks=[early_stopping_ft]\n",
    "    )\n",
    "    print(\"\\nFine-tuning complete (or stopped early).\")\n",
    "else:\n",
    "    print(\"\\nSkipping fine-tuning training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluation & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Final Evaluation on Test Set\n",
    "if 'model' in locals() and X_test_array.size > 0:\n",
    "    print(\"\\nEvaluating final model on Test Set...\")\n",
    "    test_loss, test_acc = model.evaluate(X_test_array, y_test_encoded)\n",
    "    print(f\"\\nFinal Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Final Test Accuracy: {test_acc:.4f}\")\n",
    "else:\n",
    "    print(\"\\nSkipping final evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Plot Training History\n",
    "if 'history' in locals():\n",
    "    # Combine histories safely\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs_initial = len(acc)\n",
    "\n",
    "    fine_tune_epochs_run = 0\n",
    "    if 'history_fine' in locals() and history_fine.history:\n",
    "        acc += history_fine.history.get('accuracy', [])\n",
    "        val_acc += history_fine.history.get('val_accuracy', [])\n",
    "        loss += history_fine.history.get('loss', [])\n",
    "        val_loss += history_fine.history.get('val_loss', [])\n",
    "        fine_tune_epochs_run = len(history_fine.history.get('loss', []))\n",
    "\n",
    "    epochs_range = range(epochs_initial + fine_tune_epochs_run)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.axvline(x=epochs_initial -1 , color='r', linestyle='--', label='Start Fine-tuning') # Mark fine-tuning start\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.axvline(x=epochs_initial -1, color='r', linestyle='--', label='Start Fine-tuning') # Mark fine-tuning start\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nSkipping history plotting as training did not run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Classification Report and Confusion Matrix\n",
    "if 'model' in locals() and X_test_array.size > 0 and 'y_test_encoded' in locals():\n",
    "    print(\"\\nGenerating predictions on test set...\")\n",
    "    y_pred_probs = model.predict(X_test_array)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_encoded, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test_encoded, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=label_encoder.classes_,\n",
    "                yticklabels=label_encoder.classes_)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix (VGG16)\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nSkipping Classification Report and Confusion Matrix generation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Save the Trained Model\n",
    "if 'model' in locals():\n",
    "    model_save_path = \"face_emotion_VGG16_final.keras\"\n",
    "    try:\n",
    "        model.save(model_save_path)\n",
    "        print(f\"Model saved successfully to {model_save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {e}\")\n",
    "else:\n",
    "    print(\"\\nSkipping model saving.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Qualitative Analysis (Sample Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Display Sample Predictions\n",
    "if 'model' in locals() and X_test_array.size > 0 and 'y_test_encoded' in locals():\n",
    "    num_samples = 5\n",
    "    if len(X_test_array) >= num_samples:\n",
    "        indices = np.random.choice(np.arange(len(X_test_array)), num_samples, replace=False)\n",
    "\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        for i, idx in enumerate(indices):\n",
    "            plt.subplot(1, num_samples, i+1)\n",
    "            # VGG16 input was uint8 [0, 255]\n",
    "            img_display = X_test_array[idx]\n",
    "            plt.imshow(img_display)\n",
    "            true_label = label_encoder.classes_[y_test_encoded[idx]]\n",
    "            pred_label = label_encoder.classes_[y_pred[idx]]\n",
    "            plt.title(f\"True: {true_label}\\nPred: {pred_label}\")\n",
    "            plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\nNot enough test samples to display.\")\n",
    "else:\n",
    "    print(\"\\nSkipping qualitative analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#model.summary()\n",
    "#effnet_model = model.get_layer('VGG16')\n",
    "#effnet_model.summary()\n",
    "#model.summary(expand_nested=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
