{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load cleaned data and preprocessing data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               image  emotion\n",
      "0  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      sad\n",
      "1  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...    anger\n",
      "2  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...  neutral\n",
      "3  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...     fear\n",
      "4  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...  content\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# # Load the CSV file into a DataFrame\n",
    "# df = pd.read_csv(\"cleaned_human_face_emotions.csv\")\n",
    "\n",
    "# Load the Parquet file (instead)\n",
    "df = pd.read_parquet(\"cleaned_human_face_emotions.parquet\")\n",
    "\n",
    "# Drop a column (for example, the \"qa\" column)\n",
    "df = df.drop(columns=[\"qa\"])\n",
    "\n",
    "# Print the first few rows of the updated DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9400 entries, 0 to 9399\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   image    9400 non-null   object\n",
      " 1   emotion  9400 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 147.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just have images in the first column with the emotion in the second column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 5640\n",
      "Test set size: 1880\n",
      "Validation set size: 1880\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate feature (X) and label (y)\n",
    "X = df['image']\n",
    "y = df['emotion']\n",
    "\n",
    "# Perform a stratified split to keep class distribution consistent\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,      # 80% training, 20% testing\n",
    "    random_state=42,    # for reproducibility\n",
    "    stratify=y          # important for classification\n",
    ")\n",
    "\n",
    "# Validation split from X_train if needed:\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.25,     # 25% of the training set (which is 20% of the total) -> 15% overall\n",
    "    random_state=42,\n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Test set size:\", len(X_test))\n",
    "print(\"Validation set size:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decoding and resizing images...\n",
      "X_train_array shape: (5640, 224, 224, 3)\n",
      "X_val_array shape: (1880, 224, 224, 3)\n",
      "X_test_array shape: (1880, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Image bytes -> numpy arrays\n",
    "def decode_images(image_series, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Takes a pandas Series of dictionaries, each containing {'bytes': ...}.\n",
    "    Decodes them into a list of NumPy arrays (RGB).\n",
    "    Resizes images to target_size.\n",
    "    Normalizes pixel values to [0, 1].\n",
    "\n",
    "    Returns:\n",
    "      - A NumPy array of shape (num_samples, target_size[0], target_size[1], 3)\n",
    "    \"\"\"\n",
    "    decoded_list = []\n",
    "    for item in image_series:\n",
    "        # item should be a dict like {'bytes': b'...'}\n",
    "        try:\n",
    "            img_bytes = item['bytes']\n",
    "            with Image.open(io.BytesIO(img_bytes)) as img:\n",
    "                # Convert to RGB if needed\n",
    "                img = img.convert('RGB')\n",
    "                # Resize\n",
    "                img = img.resize(target_size)\n",
    "                # Convert to array\n",
    "                arr = np.array(img, dtype=np.float32) / 255.0\n",
    "            decoded_list.append(arr)\n",
    "        except Exception as e:\n",
    "            # If there's a bad image, you might want to handle or skip it\n",
    "            print(\"Error decoding image:\", e)\n",
    "            # Optionally skip or handle it somehow. For now, let's skip:\n",
    "            # Continue with the loop\n",
    "            continue\n",
    "\n",
    "    return np.stack(decoded_list, axis=0)\n",
    "\n",
    "print(\"\\nDecoding and resizing images...\")\n",
    "\n",
    "# Decode train set\n",
    "X_train_array = decode_images(X_train, target_size=(224, 224))\n",
    "print(\"X_train_array shape:\", X_train_array.shape)\n",
    "\n",
    "# Decode val set\n",
    "X_val_array = decode_images(X_val, target_size=(224, 224))\n",
    "print(\"X_val_array shape:\", X_val_array.shape)\n",
    "\n",
    "# Decode test set\n",
    "X_test_array = decode_images(X_test, target_size=(224, 224))\n",
    "print(\"X_test_array shape:\",  X_test_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label classes found: ['anger' 'content' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise']\n",
      "Sample of encoded labels: [6 3 5 6 0 6 7 3 4 0]\n"
     ]
    }
   ],
   "source": [
    "# Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded   = label_encoder.transform(y_val)\n",
    "y_test_encoded  = label_encoder.transform(y_test)\n",
    "\n",
    "print(\"\\nLabel classes found:\", label_encoder.classes_)\n",
    "print(\"Sample of encoded labels:\", y_train_encoded[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use transfer learning with pre-trained CNN model\n",
    "convert the existing pipeline to use a pre-trained network such as ResNet50 in a transfer‐learning setup for multi-class classification using cross-entropy loss. In a transfer-learning approach, it typically replace the top (classification) layers of the pre-trained network with our own custom head and use a loss such as categorical cross-entropy (or sparse categorical cross-entropy if your labels remain as integers). We then train the added head first, and optionally fine-tune the deeper layers later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improve accuracy with data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorflow) (2.2.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rmaia\\.conda\\envs\\roxsenv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential_4 (\u001b[38;5;33mSequential\u001b[0m)       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 6s/step - accuracy: 0.1222 - loss: 2.2264 - val_accuracy: 0.1351 - val_loss: 2.0836\n",
      "Epoch 2/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 5s/step - accuracy: 0.1312 - loss: 2.1395 - val_accuracy: 0.1617 - val_loss: 2.0723\n",
      "Epoch 3/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 5s/step - accuracy: 0.1341 - loss: 2.1168 - val_accuracy: 0.1388 - val_loss: 2.0670\n",
      "Epoch 4/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 5s/step - accuracy: 0.1328 - loss: 2.1042 - val_accuracy: 0.1436 - val_loss: 2.0628\n",
      "Epoch 5/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 5s/step - accuracy: 0.1461 - loss: 2.0873 - val_accuracy: 0.1410 - val_loss: 2.0638\n",
      "Epoch 6/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 5s/step - accuracy: 0.1559 - loss: 2.0765 - val_accuracy: 0.1527 - val_loss: 2.0693\n",
      "Epoch 7/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 5s/step - accuracy: 0.1529 - loss: 2.0760 - val_accuracy: 0.1452 - val_loss: 2.0657\n",
      "Epoch 8/100\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:59\u001b[0m 4s/step - accuracy: 0.1412 - loss: 2.1080"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", message=\"Name tf.RaggedTensorSpec has already been registered\")\n",
    "\n",
    "# Assume X_train_array, X_val_array, X_test_array,\n",
    "# y_train_encoded, y_val_encoded, y_test_encoded, and label_encoder are already defined.\n",
    "num_classes = 8\n",
    "\n",
    "# Define a simple data augmentation pipeline:\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    # Random rotation: factor=0.25 corresponds roughly to ±90° rotation.\n",
    "    layers.RandomRotation(0.25),\n",
    "    # Random horizontal flip.\n",
    "    layers.RandomFlip(\"horizontal\")\n",
    "])\n",
    "\n",
    "# Pick a pre-trained model; here we use ResNet50.\n",
    "base_model = tf.keras.applications.ResNet50(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,  # Remove the default classification head.\n",
    "    weights='imagenet'\n",
    ")\n",
    "# Freeze the base model to only train the new head initially.\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build a new model on top of the base model.\n",
    "model = models.Sequential([\n",
    "    tf.keras.Input(shape=(224, 224, 3))\n",
    "    # Data augmentation layers (only active during training).\n",
    "    data_augmentation,\n",
    "    # Pre-processing can be added here if needed.\n",
    "    base_model,\n",
    "    # Global average pooling to reduce spatial dimensions.\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    # Optional dropout for regularization.\n",
    "    layers.Dropout(0.2),\n",
    "    # Final Dense layer for multi-class classification.\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Show the model summary.\n",
    "model.summary()\n",
    "\n",
    "# Train the new head.\n",
    "history = model.fit(\n",
    "    X_train_array, y_train_encoded,\n",
    "    validation_data=(X_val_array, y_val_encoded),\n",
    "    epochs=100,\n",
    "    batch_size=177\n",
    ")\n",
    "\n",
    "# Evaluate on the test set.\n",
    "test_loss, test_acc = model.evaluate(X_test_array, y_test_encoded)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Save the trained model (HDF5 format).\n",
    "model.save(\"ResNet50_basemodel.h5\")\n",
    "print(\"Model saved as ResNet50_basemodel.h5\")\n",
    "\n",
    "# Optional: Fine-tuning\n",
    "# Unfreeze the base model to allow fine-tuning.\n",
    "base_model.trainable = True\n",
    "# Freeze all layers except the last two of the base model.\n",
    "for layer in base_model.layers[:-2]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Re-compile the model with a lower learning rate.\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Continue training (fine-tuning).\n",
    "history_fine = model.fit(\n",
    "    X_train_array, y_train_encoded,\n",
    "    validation_data=(X_val_array, y_val_encoded),\n",
    "    epochs=100,\n",
    "    batch_size=177\n",
    ")\n",
    "\n",
    "final_loss, final_acc = model.evaluate(X_test_array, y_test_encoded)\n",
    "print(f\"\\nFinal Test Loss after fine-tuning: {final_loss:.4f}\")\n",
    "print(f\"Final Test Accuracy after fine-tuning: {final_acc:.4f}\")\n",
    "\n",
    "# Optionally, save the fine-tuned model too.\n",
    "model.save(\"ResNet50_basemodel_finetuned.h5\")\n",
    "print(\"Fine-tuned model saved as ResNet50_basemodel_finetuned.h5\")\n",
    "\n",
    "# Plot loss versus epochs (for initial training).\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(\"Loss vs. Epochs (Initial Training)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# If you want to also plot the fine-tuning phase's loss,\n",
    "# you can do something similar:\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_fine.history['loss'], label='Fine-tune Training Loss')\n",
    "plt.plot(history_fine.history['val_loss'], label='Fine-tune Validation Loss')\n",
    "plt.title(\"Loss vs. Epochs (Fine-tuning)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
