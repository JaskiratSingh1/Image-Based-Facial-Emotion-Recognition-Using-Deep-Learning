{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load cleaned data and preprocessing data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               image  emotion\n",
      "0  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      sad\n",
      "1  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...    anger\n",
      "2  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...  neutral\n",
      "3  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...     fear\n",
      "4  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...  content\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# # Load the CSV file into a DataFrame\n",
    "# df = pd.read_csv(\"cleaned_human_face_emotions.csv\")\n",
    "\n",
    "# Load the Parquet file (instead)\n",
    "df = pd.read_parquet(\"cleaned_human_face_emotions.parquet\")\n",
    "\n",
    "# Drop a column (for example, the \"qa\" column)\n",
    "df = df.drop(columns=[\"qa\"])\n",
    "\n",
    "# Print the first few rows of the updated DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9400 entries, 0 to 9399\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   image    9400 non-null   object\n",
      " 1   emotion  9400 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 147.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just have images in the first column with the emotion in the second column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 5640\n",
      "Test set size: 1880\n",
      "Validation set size: 1880\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate feature (X) and label (y)\n",
    "X = df['image']\n",
    "y = df['emotion']\n",
    "\n",
    "# Perform a stratified split to keep class distribution consistent\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,      # 80% training, 20% testing\n",
    "    random_state=42,    # for reproducibility\n",
    "    stratify=y          # important for classification\n",
    ")\n",
    "\n",
    "# Validation split from X_train if needed:\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.25,     # 25% of the training set (which is 20% of the total) -> 15% overall\n",
    "    random_state=42,\n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Test set size:\", len(X_test))\n",
    "print(\"Validation set size:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decoding and resizing images...\n",
      "X_train_array shape: (5640, 224, 224, 3)\n",
      "X_val_array shape: (1880, 224, 224, 3)\n",
      "X_test_array shape: (1880, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Image bytes -> numpy arrays\n",
    "def decode_images(image_series, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Takes a pandas Series of dictionaries, each containing {'bytes': ...}.\n",
    "    Decodes them into a list of NumPy arrays (RGB).\n",
    "    Resizes images to target_size.\n",
    "    Normalizes pixel values to [0, 1].\n",
    "\n",
    "    Returns:\n",
    "      - A NumPy array of shape (num_samples, target_size[0], target_size[1], 3)\n",
    "    \"\"\"\n",
    "    decoded_list = []\n",
    "    for item in image_series:\n",
    "        # item should be a dict like {'bytes': b'...'}\n",
    "        try:\n",
    "            img_bytes = item['bytes']\n",
    "            with Image.open(io.BytesIO(img_bytes)) as img:\n",
    "                # Convert to RGB if needed\n",
    "                img = img.convert('RGB')\n",
    "                # Resize\n",
    "                img = img.resize(target_size)\n",
    "                # Convert to array\n",
    "                arr = np.array(img, dtype=np.float32) / 255.0\n",
    "            decoded_list.append(arr)\n",
    "        except Exception as e:\n",
    "            # If there's a bad image, you might want to handle or skip it\n",
    "            print(\"Error decoding image:\", e)\n",
    "            # Optionally skip or handle it somehow. For now, let's skip:\n",
    "            # Continue with the loop\n",
    "            continue\n",
    "\n",
    "    return np.stack(decoded_list, axis=0)\n",
    "\n",
    "print(\"\\nDecoding and resizing images...\")\n",
    "\n",
    "# Decode train set\n",
    "X_train_array = decode_images(X_train, target_size=(224, 224))\n",
    "print(\"X_train_array shape:\", X_train_array.shape)\n",
    "\n",
    "# Decode val set\n",
    "X_val_array = decode_images(X_val, target_size=(224, 224))\n",
    "print(\"X_val_array shape:\", X_val_array.shape)\n",
    "\n",
    "# Decode test set\n",
    "X_test_array = decode_images(X_test, target_size=(224, 224))\n",
    "print(\"X_test_array shape:\",  X_test_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label classes found: ['anger' 'content' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise']\n",
      "Sample of encoded labels: [6 3 5 6 0 6 7 3 4 0]\n"
     ]
    }
   ],
   "source": [
    "# Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded   = label_encoder.transform(y_val)\n",
    "y_test_encoded  = label_encoder.transform(y_test)\n",
    "\n",
    "print(\"\\nLabel classes found:\", label_encoder.classes_)\n",
    "print(\"Sample of encoded labels:\", y_train_encoded[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use transfer learning with pre-trained CNN model\n",
    "convert the existing pipeline to use a pre-trained network such as ResNet50 in a transfer‐learning setup for multi-class classification using cross-entropy loss. In a transfer-learning approach, it typically replace the top (classification) layers of the pre-trained network with our own custom head and use a loss such as categorical cross-entropy (or sparse categorical cross-entropy if your labels remain as integers). We then train the added head first, and optionally fine-tune the deeper layers later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Again assume: X_train_array, X_val_array, X_test_array, and y_train_encoded, y_val_encoded, y_test_encoded.\n",
    "# And num_classes is defined.\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Define a data augmentation pipeline.\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    # Randomly rotate images up to 25% (roughly ±90° when set to 0.25, or adjust as needed).\n",
    "    layers.RandomRotation(0.25),\n",
    "    # Randomly flip images horizontally.\n",
    "    layers.RandomFlip(\"horizontal\")\n",
    "])\n",
    "\n",
    "# Use VGG16 as the base pre-trained model.\n",
    "base_model = tf.keras.applications.VGG16(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Freeze the base model initially.\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build the model.\n",
    "model = models.Sequential([\n",
    "    tf.keras.Input(shape=(224, 224, 3))\n",
    "    # Data augmentation layers (active only during training).\n",
    "    data_augmentation,\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.5),  # VGG16 sometimes benefits from a higher dropout.\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with sparse categorical cross entropy loss.\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the classifier head.\n",
    "history = model.fit(\n",
    "    X_train_array, y_train_encoded,\n",
    "    validation_data=(X_val_array, y_val_encoded),\n",
    "    epochs=5,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate on test data.\n",
    "test_loss, test_acc = model.evaluate(X_test_array, y_test_encoded)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Save the trained model (HDF5 format).\n",
    "model.save(\"VGG16_basemodel.h5\")\n",
    "print(\"Model saved as VGG16_basemodel.h5\")\n",
    "\n",
    "# Fine-tuning:\n",
    "# Unfreeze all first\n",
    "base_model.trainable = True\n",
    "\n",
    "# Freeze all layers except the last two.\n",
    "for layer in base_model.layers[:-2]:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_fine = model.fit(\n",
    "    X_train_array, y_train_encoded,\n",
    "    validation_data=(X_val_array, y_val_encoded),\n",
    "    epochs=5,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "final_loss, final_acc = model.evaluate(X_test_array, y_test_encoded)\n",
    "print(f\"\\nFinal Test Loss after fine-tuning: {final_loss:.4f}\")\n",
    "print(f\"Final Test Accuracy after fine-tuning: {final_acc:.4f}\")\n",
    "\n",
    "# save the fine-tuned model\n",
    "model.save(\"VGG16_basemodel_finetuned.h5\")\n",
    "print(\"Fine-tuned model saved as VGG16_basemodel_finetuned.h5\")\n",
    "\n",
    "# Plot loss versus epochs (for initial training).\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(\"Loss vs. Epochs (Initial Training)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# If you want to also plot the fine-tuning phase's loss,\n",
    "# you can do something similar:\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_fine.history['loss'], label='Fine-tune Training Loss')\n",
    "plt.plot(history_fine.history['val_loss'], label='Fine-tune Validation Loss')\n",
    "plt.title(\"Loss vs. Epochs (Fine-tuning)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
